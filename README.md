# Retail Insights Assistant ğŸ›ï¸

## Enterprise-Grade Multi-Agent GenAI System for Retail Analytics

A sophisticated GenAI-powered solution that enables natural language querying of retail sales data, automated insight generation, and scalable analytics for organizations dealing with large-scale retail datasets.

---

## ğŸ¯ Overview

The Retail Insights Assistant is a production-ready multi-agent system that combines:
- **Advanced LLM Integration** (OpenAI GPT-4 / Google Gemini)
- **Multi-Agent Architecture** (LangGraph orchestration)
- **Efficient Data Processing** (DuckDB for OLAP queries)
- **Intuitive UI** (Streamlit interface)
- **Scalable Design** (Architecture for 100GB+ datasets)

### Key Capabilities

âœ… **Conversational Q&A**: Ask business questions in natural language  
âœ… **Automated Summarization**: Generate comprehensive insights reports  
âœ… **Multi-Agent System**: 4 specialized agents working in orchestration  
âœ… **Data Validation**: Ensures accuracy and quality of results  
âœ… **Scalable Architecture**: Designed for enterprise-scale data (100GB+)

---

## ğŸ—ï¸ System Architecture

### Multi-Agent Workflow

```
User Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 1: Query Resolution Agent                â”‚
â”‚  â€¢ Interprets natural language                  â”‚
â”‚  â€¢ Extracts entities (regions, dates, metrics)  â”‚
â”‚  â€¢ Generates SQL queries                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 2: Data Extraction Agent                 â”‚
â”‚  â€¢ Executes SQL on DuckDB                       â”‚
â”‚  â€¢ Retrieves relevant data                      â”‚
â”‚  â€¢ Generates data summaries                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 3: Validation Agent                      â”‚
â”‚  â€¢ Validates result quality                     â”‚
â”‚  â€¢ Checks data integrity                        â”‚
â”‚  â€¢ Flags anomalies                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 4: Response Generation Agent             â”‚
â”‚  â€¢ Creates natural language responses           â”‚
â”‚  â€¢ Provides business insights                   â”‚
â”‚  â€¢ Formats results clearly                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Answer to User
```

### Technology Stack

- **LLM Framework**: LangChain + LangGraph
- **LLM Providers**: OpenAI GPT-4 / Google Gemini
- **Database**: DuckDB (embedded OLAP database)
- **UI Framework**: Streamlit
- **Data Processing**: Pandas, NumPy
- **Language**: Python 3.9+

---

## ğŸ“¦ Project Structure

```
retail-insights-assistant/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ query_agent.py          # Agent 1: Query resolution
â”‚   â”œâ”€â”€ extraction_agent.py     # Agent 2: Data extraction
â”‚   â”œâ”€â”€ validation_agent.py     # Agent 3: Result validation
â”‚   â”œâ”€â”€ response_agent.py       # Agent 4: Response generation
â”‚   â””â”€â”€ orchestrator.py         # LangGraph orchestration
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_layer.py           # DuckDB integration
â”‚   â””â”€â”€ llm_utils.py            # LLM utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ generate_data.py        # Sample data generator
â”‚   â””â”€â”€ sales_data.csv          # Generated data (not in repo)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agents.py          # Unit tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md         # Detailed architecture
â”‚   â””â”€â”€ SCALABILITY.md          # 100GB+ design
â”œâ”€â”€ screenshots/                # Demo screenshots
â”œâ”€â”€ app.py                      # Streamlit UI
â”œâ”€â”€ config.py                   # Configuration
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ .env.example                # Environment template
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9 or higher
- OpenAI API key OR Google Gemini API key
- 4GB RAM minimum (8GB recommended)

### Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd retail-insights-assistant
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env and add your API key:
# For OpenAI: OPENAI_API_KEY=your_key_here
# For Gemini: GOOGLE_API_KEY=your_key_here
```

5. **Generate sample data**
```bash
python data/generate_data.py
```
This creates `data/sales_data.csv` with 50,000 sample transactions.

6. **Run the application**
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

---

## ğŸ’» Usage

### Conversational Q&A Mode

Ask natural language questions like:
- "What were total sales in Q3 2023?"
- "Which region had the highest growth in 2023?"
- "Top 5 products by profit?"
- "Compare Electronics vs Clothing category revenue"
- "Show monthly sales trend for the North region"

### Summary Mode

Generate automated comprehensive reports covering:
- Overall performance metrics
- Regional analysis
- Category breakdowns
- Year-over-year trends
- Channel performance

### Data Explorer

Visualize key metrics with:
- Interactive charts
- Regional breakdown
- Category performance
- Yearly trends

---

## ğŸ”§ Configuration

### LLM Selection

Edit `.env` to choose your LLM provider:

**Option 1: OpenAI (Recommended)**
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4-turbo-preview
```

**Option 2: Google Gemini**
```env
LLM_PROVIDER=google
GOOGLE_API_KEY=your-key-here
GEMINI_MODEL=gemini-pro
```

### Advanced Settings

```env
MAX_CONTEXT_LENGTH=4000      # Maximum tokens for context
TEMPERATURE=0.1              # LLM temperature (0.0 = deterministic)
MAX_TOKENS=2000              # Maximum response tokens
```

---

## ğŸ§ª Testing

Run the test suite:
```bash
pytest tests/ -v
```

Test individual components:
```bash
# Test query agent
python -c "from agents.query_agent import QueryResolutionAgent; agent = QueryResolutionAgent(); print(agent.resolve_query('What were total sales?'))"

# Test data layer
python -c "from utils.data_layer import get_data_layer; dl = get_data_layer(); print(dl.get_summary_stats())"
```

---

## ğŸ“Š Sample Questions & Outputs

### Example 1: Revenue Analysis
**Q**: "What were total sales in 2023?"  
**A**: "In 2023, total sales reached $XX.XX million across X,XXX transactions, representing a YY% increase compared to 2022..."

### Example 2: Regional Comparison
**Q**: "Which region performed best?"  
**A**: "The West region led in revenue with $X.XX million (XX% of total), followed by North ($X.XX million, XX%)..."

### Example 3: Category Insights
**Q**: "Top 3 categories by profit margin?"  
**A**: "Electronics achieved the highest profit margin at XX%, generating $X.XX million in profit..."

---

## ğŸ” Security & Privacy

- API keys stored in `.env` (never committed to repo)
- No data leaves your local environment (except LLM API calls)
- DuckDB database is local and embedded
- All processing happens on your machine

---

## ğŸ“ Project Highlights

### Technical Excellence
âœ… **Multi-Agent Design**: 4 specialized agents with clear separation of concerns  
âœ… **LangGraph Orchestration**: State-based workflow management  
âœ… **Efficient Querying**: DuckDB for sub-second analytics  
âœ… **Error Handling**: Graceful failure recovery at each stage  
âœ… **Validation Layer**: Ensures data quality and accuracy

### Production-Ready Features
âœ… **Configurable LLM**: Support for multiple providers  
âœ… **Conversation History**: Track query patterns  
âœ… **Data Explorer**: Visual analytics  
âœ… **Export Functionality**: Download reports  
âœ… **Extensible Architecture**: Easy to add new agents

---

## ğŸ“ˆ Scalability to 100GB+

See [docs/SCALABILITY.md](docs/SCALABILITY.md) for detailed architecture.

### Key Strategies

1. **Data Lake Architecture**: Store raw data in S3/GCS/Azure
2. **Distributed Processing**: Use PySpark/Dask for ETL
3. **Data Warehouse**: Snowflake/BigQuery for OLAP
4. **Vector Indexing**: FAISS/Pinecone for semantic search
5. **Caching Layer**: Redis for frequent queries
6. **Query Optimization**: Partitioning, columnar storage
7. **RAG Pattern**: Retrieve relevant subsets before querying

**Estimated Performance at Scale**:
- **100GB Dataset**: < 2 second query response
- **1TB Dataset**: < 5 second query response
- **10TB Dataset**: < 10 second query response (with proper indexing)

---

## ğŸ› ï¸ Assumptions & Limitations

### Current Implementation Assumptions
- Data fits in memory (< 5GB CSV recommended for local demo)
- Single-user application (no concurrent access)
- English language queries only
- Structured tabular data (CSV format)
- Date range: 2021-2023 (configurable)

### Known Limitations
- No real-time streaming data support
- Limited to predefined schema
- No user authentication/authorization
- Single database instance
- No distributed query execution

### Planned Improvements
- [ ] Multi-user support with authentication
- [ ] Real-time data ingestion
- [ ] Support for unstructured data (PDFs, images)
- [ ] Advanced visualizations (Plotly, charts)
- [ ] Query caching for performance
- [ ] API endpoint for programmatic access
- [ ] Multi-language support
- [ ] Advanced RAG with vector embeddings

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ“„ License

MIT License - see LICENSE file for details

---

## ğŸ‘¥ Author

**Your Name**  
Email: your.email@example.com  
GitHub: @yourusername  
LinkedIn: linkedin.com/in/yourprofile

---

## ğŸ™ Acknowledgments

- **LangChain**: For the excellent LLM framework
- **LangGraph**: For multi-agent orchestration
- **DuckDB**: For blazing-fast analytics
- **Streamlit**: For the beautiful UI framework
- **OpenAI/Google**: For powerful LLM APIs

---

## ğŸ“ Support

For questions or issues:
- Open a GitHub issue
- Email: support@yourcompany.com
- Documentation: [docs/](docs/)

---

**Built with â¤ï¸ for Blend360 GenAI Interview Assignment**

*Demonstrating enterprise-grade GenAI engineering, scalable architecture design, and production-ready implementation.*
